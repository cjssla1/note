자연어 처리
Bag of Words : 단어들의 빈도를 표로 표현한 것
장점: 문장의 유사도를 알 수 있다. (각각의 빈도를 나타낸 벡터를 내적한 값)
단점: 단어들의 순서를 무시한다. Sparsity, 단어의 개수가 커짐에 따라 입력이 커져 힘들다. 빈도가 많을수록 더 큰 힘을 얻는다. 처음 본 단어를 처리 못한다.

N-gram: n개의 토큰(문자, 형태소, 단어)으로 구성
N이 1 일 때 유니그램(unigram), 2일 때 바이그램(bigram), 3일 때 트라이그램(trigram)
장점 : 단어의 순서 조금 유지, 다음 단어 예측 가능, 오타 발견 가능

TF-IDF( Term Frequency * Inverse Document Frequency ) : 각 단어와 문서의 연관성을 수치도 나타낸 값
TF : 문서에서 단어가 출현한 빈도, TF score = 단어 / 전체 단어, 빈도가 높을수록 문장에 중요할 것이다.라는 가정 그러나 관사나 문법이 더 많이 출현하기에 TF만으론 부족하다.
IDF: Log( 전체 문장 개수 / 출현한 문장 개수 + 1(스무딩)) 문장에 관계없이 자주 나오는 단어에 불이익을 준다.

자연어처리의 유사도 판단 방법: 코사인 유사도, 유클리드 거리
유클리드 거리 : 피타고라스 정리를 이용. 백터 크기 문제 발생
코사인 유사도 : A'B내적 / A크기*B크기
